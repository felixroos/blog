{"componentChunkName":"component---node-modules-gatsby-theme-blog-core-src-templates-post-query-js","path":"/rhythmical-chords/","result":{"data":{"site":{"siteMetadata":{"title":"Loophole Letters","social":[{"name":"github","url":"https://github.com/felixroos"},{"name":"GitHub","url":"https://github.com/gatsbyjs"}]}},"blogPost":{"__typename":"MdxBlogPost","id":"2b49a6a1-d665-5745-b2b9-71579ed46c30","excerpt":"To bring rhythmical one step closer to being a hackable backing track player, I want to implement one of the most important things: chord…","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Rhythmical Chords\",\n  \"date\": \"2020-07-30T00:00:00.000Z\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"To bring rhythmical one step closer to being a hackable backing track player, I want to implement one of the most important things: chord symbols.\"), mdx(\"p\", null, \"Disclaimer: To get the most out of this post, you might want to read those posts first:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://felixroos.github.io/blog/rhythmical-arrays/\"\n  }), \"Rhythmical Arrays\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://felixroos.github.io/blog/rhythmical-objects/\"\n  }), \"Rhythmical Objects\"))), mdx(\"p\", null, \"After this post, we will be able play chords like this:\"), mdx(Player, {\n    instruments: {\n      tinypiano: tinypiano\n    },\n    fold: false,\n    events: renderRhythmObject({\n      duration: 64,\n      sequential: [['Fm7', 'Bbm7', 'Eb7', 'Ab^7'], ['Db^7', ['Dm7', 'G7'], 'C^7', '_'], ['Cm7', 'Fm7', 'Bb7', 'Eb^7'], ['Ab^7', ['Am7', 'D7'], 'G^7', '_'], ['Am7', 'D7', 'G^7', '_'], ['F#m7b5', 'B7b9', 'E^7', 'C7b13'], ['Fm7', 'Bbm7', 'Eb7', 'Ab^7'], ['Db^7', 'DbmM7', 'Cm7', 'Bo7'], ['Bbm7', 'Eb7', 'Ab^7', ['Gm7b5', 'C7b9']]]\n    }).reduce(tieReducer(), []).reduce(voicingReducer(lefthand, ['G3', 'G5']), []),\n    mdxType: \"Player\"\n  }), mdx(\"details\", null, mdx(\"summary\", null, \"show source\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Player\\n  instruments={{ tinypiano }}\\n  fold={false}\\n  events={renderRhythmObject({\\n    duration: 64,\\n    sequential: [\\n      ['Fm7', 'Bbm7', 'Eb7', 'Ab^7'],\\n      ['Db^7', ['Dm7', 'G7'], 'C^7', '_'],\\n      ['Cm7', 'Fm7', 'Bb7', 'Eb^7'],\\n      ['Ab^7', ['Am7', 'D7'], 'G^7', '_'],\\n      ['Am7', 'D7', 'G^7', '_'],\\n      ['F#m7b5', 'B7b9', 'E^7', 'C7b13'],\\n      ['Fm7', 'Bbm7', 'Eb7', 'Ab^7'],\\n      ['Db^7', 'DbmM7', 'Cm7', 'Bo7'],\\n      ['Bbm7', 'Eb7', 'Ab^7', ['Gm7b5', 'C7b9']]\\n    ]\\n  })\\n    .reduce(tieReducer(), [])\\n    .reduce(voicingReducer(lefthand, ['G3', 'G5']), [])}\\n/>\\n\"))), mdx(\"br\", null), mdx(\"p\", null, \"Without having anything implemented yet, let\\u2019s \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://felixroos.github.io/blog/rhythmical-objects/\"\n  }), \"render\"), \" the following two bars of major chords:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"renderRhythmObject({\\n  duration: 8,\\n  sequential: [['F', 'G'], 'C']\\n});\\n\")), mdx(\"p\", null, \"\\u2026and look at the result:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"[\\n  {\\n    value: 'F',\\n    time: 0,\\n    duration: 2\\n  },\\n  {\\n    value: 'G',\\n    time: 2,\\n    duration: 2\\n  },\\n  {\\n    value: 'C',\\n    time: 4,\\n    duration: 4\\n  }\\n];\\n\")), mdx(\"p\", null, \"\\u2026obviously, we cannot use that for playback, as these are chord symbols, and we need single notes with octaves.\"), mdx(\"h2\", {\n    \"id\": \"most-basic-chord-reducer\"\n  }, \"Most Basic Chord Reducer\"), mdx(\"p\", null, \"As our goal is to get playable events, we need to transform the chord symbols to notes, using \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/tonaljs/tonal/tree/master/packages/chord#chordgetname-string-\"\n  }), \"Chord.get\"), \" and \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/tonaljs/tonal/tree/master/packages/note#transposenote-string-interval-string--string\"\n  }), \"Note.transpose\"), \" of \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/tonaljs/tonal\"\n  }), \"tonaljs\"), \":\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-ts\"\n  }), \"import { Chord, Note } from '@tonaljs/tonal';\\n\\nexport function chordReducer(events, event, index, array) {\\n  if (typeof event.value === 'string') {\\n    const { intervals, tonic } = Chord.get(event.value);\\n    const notes = intervals.map((interval) =>\\n      Note.transpose(tonic + '3', interval)\\n    );\\n    return events.concat(notes.map((note) => ({ ...event, value: note })));\\n  }\\n  return events;\\n}\\n\")), mdx(\"p\", null, \"to apply the reducer, we can now just use \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://developer.mozilla.org/de/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce\"\n  }), \"reduce\"), \":\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"renderRhythmObject({\\n  duration: 8,\\n  sequential: [['F', 'G'], 'C']\\n}).reduce(chordReducer, []);\\n\")), mdx(\"p\", null, \"Result:\"), mdx(\"div\", {\n    style: {\n      maxHeight: 400,\n      overflow: 'auto',\n      borderRadius: 10,\n      marginBottom: 10\n    }\n  }, mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"[\\n  {\\n    value: 'F3',\\n    time: 0,\\n    duration: 2\\n  },\\n  {\\n    value: 'A3',\\n    time: 0,\\n    duration: 2\\n  },\\n  {\\n    value: 'C4',\\n    time: 0,\\n    duration: 2\\n  },\\n  {\\n    value: 'G3',\\n    time: 2,\\n    duration: 2\\n  },\\n  {\\n    value: 'B3',\\n    time: 2,\\n    duration: 2\\n  },\\n  {\\n    value: 'D4',\\n    time: 2,\\n    duration: 2\\n  },\\n  {\\n    value: 'C3',\\n    time: 4,\\n    duration: 4\\n  },\\n  {\\n    value: 'E3',\\n    time: 4,\\n    duration: 4\\n  },\\n  {\\n    value: 'G3',\\n    time: 4,\\n    duration: 4\\n  }\\n];\\n\"))), mdx(\"p\", null, \"\\u2026which we can now play back:\"), mdx(Player, {\n    instruments: {\n      tinypiano: tinypiano\n    },\n    fold: false,\n    events: renderRhythmObject({\n      duration: 8,\n      sequential: [['F', 'G'], 'C']\n    }).reduce(chordReducer, []),\n    mdxType: \"Player\"\n  }), mdx(\"details\", null, mdx(\"summary\", null, \"show source\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Player\\n  instruments={{ tinypiano }}\\n  fold={false}\\n  events={renderRhythmObject({\\n    duration: 8,\\n    sequential: [['F', 'G'], 'C']\\n  }).reduce(chordReducer, [])}\\n/>\\n\"))), mdx(\"br\", null), mdx(\"h2\", {\n    \"id\": \"is-this-good-music-yet\"\n  }, \"Is this good music yet?\"), mdx(\"p\", null, \"Even besides the fact that this is played back by a cheap piano without rhythm, you might not be satisfied with the way the chords are played.\"), mdx(\"p\", null, \"A good pianist would never play chords like this, as their voices are moving with big steps. The voice leading would be much better if the end result sounded something like this:\"), mdx(Player, {\n    fold: false,\n    instruments: {\n      tinypiano: tinypiano\n    },\n    events: renderRhythmObject({\n      duration: 8,\n      sequential: [[{\n        parallel: ['F3', 'A3', 'C4']\n      }, {\n        parallel: ['D3', 'G3', 'B3']\n      }], {\n        parallel: ['E3', 'G3', 'C4']\n      }]\n    }),\n    mdxType: \"Player\"\n  }), mdx(\"details\", null, mdx(\"summary\", null, \"show source\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Player\\n  fold={false}\\n  instruments={{ tinypiano }}\\n  events={renderRhythmObject({\\n    duration: 8,\\n    sequential: [\\n      [{ parallel: ['F3', 'A3', 'C4'] }, { parallel: ['D3', 'G3', 'B3'] }],\\n      { parallel: ['E3', 'G3', 'C4'] }\\n    ]\\n  })}\\n/>\\n\"))), mdx(\"p\", null, \"Here, we start on F major in \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://en.wikipedia.org/wiki/Root_position\"\n  }), \"root position\"), \" (1 3 5), transition to G major in 2nd inversion (5 1 3) to land on C major in 1st inversion (3 5 1).\"), mdx(\"p\", null, \"If we look at the movement between individual notes (voices), we only have small steps between 0 and 3 semitones, as opposed to 2-5 semitones in the previous example.\\nThe result is a much smoother sound.\"), mdx(\"h2\", {\n    \"id\": \"voicings--voice-leading\"\n  }, \"Voicings & Voice leading\"), mdx(\"p\", null, \"The problem above brings us to the topic of Voicings and Voice Leading.\"), mdx(\"p\", null, \"A \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"voicing\"), \" of a chord is one of many ways to play it, like different inversions. Another way to voice chords is by using wider intervals or doubling notes in different octaves. If you have no clue what I\\u2019m talking about, \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.youtube.com/watch?v=VR3o45Pwx9Y\"\n  }), \"watch this video\"), \".\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Voice Leading\"), \" describes the transition between different voicings of chords, with the general aim to create smooth transitions.\"), mdx(\"h2\", {\n    \"id\": \"two-approaches-to-algorithmic-voicings\"\n  }, \"Two approaches to algorithmic voicings\"), mdx(\"p\", null, \"So far, I came across two approaches to generate voicings automatically:\"), mdx(\"h3\", {\n    \"id\": \"voicing-dictionaries\"\n  }, \"Voicing Dictionaries\"), mdx(\"p\", null, \"Many applications (like iReal pro) use dictionaries that contain multiple voicings for each chord, then picking the one with the best voice leading.\\nThis is similar to how beginner and intermediate improvising piano players learn chords: Practising different voicings and pressing them on the fly.\\nThis is the approach that I want to implement today.\"), mdx(\"h3\", {\n    \"id\": \"voicing-permutation\"\n  }, \"Voicing Permutation\"), mdx(\"p\", null, \"More advanced improvisers will think in terms of scales/modes and voicings that fit inside, which offers much more freedom.\\nThis approach can be mapped by using permutation: Taking all possible notes that can be selected for a chord, and going through all possible combinations one by one.\\nAs there are almost endless combinations, especially for chords with more notes, we need to come up with some rules that filter out combinations we do not want + find a way to permutate efficiently.\\nThis can be done via \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://felixroos.github.io/blog/combinatorial-search/\"\n  }), \"combinatorial search\"), \", which will be the topic for a future post.\"), mdx(\"h2\", {\n    \"id\": \"implementing-a-voicing-dictionary\"\n  }, \"Implementing a Voicing Dictionary\"), mdx(\"p\", null, \"A small fragment of a voicing dictionary could look like this:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"export const lefthand = {\\n  m7: ['3m 5P 7m 9M', '-2M 2M 3m 5P', '7m 9M 10m 12P'],\\n  '7': ['3M 6M 7m 9M', '-2M 2M 3M 6M', '7m 9M 10M 13M'],\\n  '^7': ['3M 5P 7M 9M', '-2m 2M 3M 5P', '7M 9M 10M 12P']\\n};\\n\")), mdx(\"p\", null, \"These are typical \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.youtube.com/watch?v=5uoD6LfaDoE\"\n  }), \"rootless lefthand voicings\"), \", notated using .\\nIf we now want to resolve chords with good voice leading, we can do it like this:\"), mdx(\"div\", {\n    style: {\n      maxHeight: 400,\n      overflow: 'auto',\n      borderRadius: 10,\n      marginBottom: 10\n    }\n  }, mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-ts\"\n  }), \"import { Chord, Note } from '@tonaljs/tonal';\\n\\nexport const voicingDictionaryReducer = (dictionary) => (events, event) => {\\n  if (typeof event.value !== 'string') {\\n    return events;\\n  }\\n  const { tonic, aliases } = Chord.get(event.value);\\n  const symbol = Object.keys(dictionary).find((_symbol) =>\\n    aliases.includes(_symbol)\\n  );\\n  if (!symbol) {\\n    console.log(`no voicings found for chord \\\"${event.value}\\\"`);\\n    return events;\\n  }\\n  let intervals;\\n  const voicings = dictionary[symbol].map((i) => i.split(' ')); // split interval strings\\n  const root = tonic + '3';\\n  const bass = tonic + '2';\\n  if (!events.length) {\\n    // first chord => just use first voicing\\n    intervals = voicings[0];\\n  } else {\\n    // not first chord => find smoothest voicing\\n    const lastNote = events[events.length - 1].value; // last voiced note (top note)\\n    // calculates the distance between the last note and the given voicings top note\\n    const diff = (voicing) =>\\n      Math.abs(\\n        Note.midi(lastNote) -\\n          Note.midi(Note.transpose(root, voicing[voicing.length - 1]))\\n      );\\n    // sort voicings by lowest top note difference\\n    intervals = voicings.sort((a, b) => diff(a) - diff(b))[0];\\n  }\\n  // transpose to root\\n  const notes = intervals.map((interval) => Note.transpose(root, interval));\\n  return events\\n    .concat([{ ...event, value: bass }])\\n    .concat(notes.map((note) => ({ ...event, value: note })));\\n};\\n\"))), mdx(\"p\", null, \"Now, a 251 sounds like this:\"), mdx(Player, {\n    fold: false,\n    instruments: {\n      tinypiano: tinypiano\n    },\n    events: renderRhythmObject({\n      duration: 8,\n      sequential: [['Dm7', 'G7'], 'C^7']\n    }).reduce(voicingDictionaryReducer(lefthandBad), []),\n    mdxType: \"Player\"\n  }), mdx(\"p\", null, \"Ahhh.. yeahhh, niccce. Let\\u2019s try a tune that only uses 251s but goes through different tonal centers, like joy spring:\"), mdx(Player, {\n    fold: false,\n    instruments: {\n      tinypiano: tinypiano\n    },\n    events: renderRhythmObject({\n      duration: 64,\n      sequential: [['F^7', ['Gm7', 'C7'], 'F^7', ['Bbm7', 'Eb7']], [['Am7', 'Ab7'], ['Gm7', 'C7'], 'F^7', ['Abm7', 'Db7']], ['Gb^7', ['Abm7', 'Db7'], 'Gb^7', ['Bm7', 'E7']], [['Bbm7', 'A7'], ['Abm7', 'Db7'], 'Gb^7', ['Am7', 'D7']], ['G^7', ['Gm7', 'C7'], 'F^7', ['Fm7', 'Bb7']], ['Eb^7', ['Abm7', 'Db7'], 'Gb^7', ['Gm7', 'C7']], ['F^7', ['Gm7', 'C7'], 'F^7', ['Bbm7', 'Eb7']], [['Am7', 'Ab7'], ['Gm7', 'C7'], 'F^7', ['Gm7', 'C7']]]\n    }).reduce(voicingDictionaryReducer(lefthandBad), []),\n    mdxType: \"Player\"\n  }), mdx(\"details\", null, mdx(\"summary\", null, \"show source\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Player\\n  fold={false}\\n  instruments={{ tinypiano }}\\n  events={renderRhythmObject({\\n    duration: 64,\\n    sequential: [\\n      ['F^7', ['Gm7', 'C7'], 'F^7', ['Bbm7', 'Eb7']],\\n      [['Am7', 'Ab7'], ['Gm7', 'C7'], 'F^7', ['Abm7', 'Db7']],\\n      ['Gb^7', ['Abm7', 'Db7'], 'Gb^7', ['Bm7', 'E7']],\\n      [['Bbm7', 'A7'], ['Abm7', 'Db7'], 'Gb^7', ['Am7', 'D7']],\\n      ['G^7', ['Gm7', 'C7'], 'F^7', ['Fm7', 'Bb7']],\\n      ['Eb^7', ['Abm7', 'Db7'], 'Gb^7', ['Gm7', 'C7']],\\n      ['F^7', ['Gm7', 'C7'], 'F^7', ['Bbm7', 'Eb7']],\\n      [['Am7', 'Ab7'], ['Gm7', 'C7'], 'F^7', ['Gm7', 'C7']]\\n    ]\\n  }).reduce(voicingDictionaryReducer(lefthand), [])}\\n/>\\n\"))), mdx(\"br\", null), mdx(\"h3\", {\n    \"id\": \"observations\"\n  }, \"Observations\"), mdx(\"p\", null, \"Apart from the fact that this still sounds robotic due to the lame rhythm and non existing articulation, we can observe:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"the basic voice leading works good\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sometimes, it still jumps after getting too low\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"this is (partly) good, as voicings that are too low sound muddy\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"for many tunes (like joy spring), it is inevitable that the tightest possible voice leading is going out of range at some point\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"so at some point, a non optimal voice leading has to be chosen to get back to the sugar range\")), mdx(\"h3\", {\n    \"id\": \"range-considerations\"\n  }, \"Range Considerations\"), mdx(\"p\", null, \"Let\\u2019s review, how we are transposing the intervals to get the notes:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-ts\"\n  }), \"const root = tonic + '3';\\nconst notes = intervals.map((interval) => Note.transpose(root, interval));\\n\")), mdx(\"p\", null, \"This will give us a lowest possible root of C3 and a highest of B3.\"), mdx(\"p\", null, \"If we use the following intervals:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"export const lefthand = {\\n  m7: ['3m 5P 7m 9M', '-2M 2M 3m 5P', '7m 9M 10m 12P'],\\n  '7': ['3M 6M 7m 9M', '-2M 2M 3M 6M', '7m 9M 10M 13M'],\\n  '^7': ['3M 5P 7M 9M', '-2m 2M 3M 5P', '7M 9M 10M 12P']\\n};\\n\")), mdx(\"p\", null, \"\\u2026 we have a minimum transposition of -2M and a maximum of 13M. Applying those to our min and max roots we get a note range of:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lowest note: C3 - 2M = Bb2\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"highest note: B3 + 13M = G#4\")), mdx(\"p\", null, \"To test some range edge cases, I want to create an example where the voicings get really low. As the first voicing will always use the first interval set:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"if (!events.length) {\\n  // first chord => just use first voicing\\n  intervals = voicings[0];\\n}\\n\")), mdx(\"p\", null, \"\\u2026which is:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u20183m 5P 7m 9M\\u2019 for m7\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u20183M 6M 7m 9M\\u2019 for 7\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\u20183M 5P 7M 9M\\u2019 for ^7\")), mdx(\"p\", null, \"\\u2026 we will not even use the min or max intervals. If we want to reach them, we have to construct chords so that their smoothest voice leading will go down:\"), mdx(Player, {\n    fold: false,\n    instruments: {\n      tinypiano: tinypiano\n    },\n    events: renderRhythmObject({\n      duration: 6,\n      sequential: ['Cm7', 'Em7', 'Dm7', {\n        value: 'Cm7',\n        duration: 2\n      }, 'Bm7']\n    }).reduce(voicingDictionaryReducer(lefthandBad), []),\n    mdxType: \"Player\"\n  }), mdx(\"details\", null, mdx(\"summary\", null, \"show source\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Player\\n  fold={false}\\n  instruments={{ tinypiano }}\\n  events={renderRhythmObject({\\n    duration: 6,\\n    sequential: ['Cm7', 'Em7', 'Dm7', { value: 'Cm7', duration: 2 }, 'Bm7']\\n  }).reduce(voicingDictionaryReducer(lefthand), [])}\\n/>\\n\"))), mdx(\"p\", null, \"Now we reach the lowest possible note (Bb2) on the second Cm7 (the long one). This is kind of low, but still more or less acceptable. What\\u2019s less acceptable, is the last chord:\"), mdx(\"p\", null, \"I\\u2019ve set up the Bm7 to create a disjoint after the low Cm7. It may not sound unpleasant but for the goal of smooth voice leading, the Bm7 goes higher than it should.\"), mdx(\"p\", null, \"If we add another, even lower octave to our m7 voicings:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-ts\"\n  }), \"{\\nm7: ['3m 5P 7m 9M', '-6M -4P -2M 2M', '-2M 2M 3m 5P', '7m 9M 10m 12P'],\\n/* */\\n}\\n\")), mdx(\"p\", null, \"\\u2026 we get this:\"), mdx(Player, {\n    fold: false,\n    instruments: {\n      tinypiano: tinypiano\n    },\n    events: renderRhythmObject({\n      duration: 6,\n      sequential: ['Cm7', 'Em7', 'Dm7', {\n        value: 'Cm7',\n        duration: 2\n      }, 'Bm7']\n    }).reduce(voicingDictionaryReducer({\n      m7: ['3m 5P 7m 9M', '-6M -4P -2M 2M', '-2M 2M 3m 5P', '7m 9M 10m 12P'],\n      '7': ['3M 6M 7m 9M', '-6m -3m -2M 2M', '-2M 2M 3M 6M', '7m 9M 10M 13M'],\n      '^7': ['3M 5P 7M 9M', '-2m 2M 3M 5P', '7M 9M 10M 12P']\n    }), []),\n    mdxType: \"Player\"\n  }), mdx(\"p\", null, \"Now, the Bm7 does not \\u201Covershoot\\u201D and leads much smoother to the higher Cm7. Ok fine, so should we just use that addition?\"), mdx(\"p\", null, \"Before we do that, let\\u2019s modify the example slightly, spinning an extra round to get even lower:\"), mdx(Player, {\n    fold: false,\n    instruments: {\n      tinypiano: tinypiano\n    },\n    events: renderRhythmObject({\n      duration: 12,\n      sequential: ['Cm7', 'Em7', 'Db^7', 'Cm7', 'Em7', 'Dm7', {\n        value: 'Cm7',\n        duration: 2\n      }, 'Bm7']\n    }).reduce(voicingDictionaryReducer({\n      m7: ['3m 5P 7m 9M', '-6M -4P -2M 2M', '-2M 2M 3m 5P', '7m 9M 10m 12P'],\n      '7': ['3M 6M 7m 9M', '-6m -3m -2M 2M', '-2M 2M 3M 6M', '7m 9M 10M 13M'],\n      '^7': ['3M 5P 7M 9M', '-2m 2M 3M 5P', '7M 9M 10M 12P']\n    }), []),\n    mdxType: \"Player\"\n  }), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"[\\n  'Cm7',\\n  'Em7',\\n  'Db^7',\\n  'Cm7',\\n  'Em7',\\n  'Dm7',\\n  { value: 'Cm7', duration: 2 },\\n  'Bm7'\\n];\\n\")), mdx(\"p\", null, \"Here, we are getting much too low on the longer Cm7\\u2026\"), mdx(\"h3\", {\n    \"id\": \"the-dilemma\"\n  }, \"The dilemma\"), mdx(\"p\", null, \"So now we have the classic coding dilemma: We had a problem (Bm7 did not go low enough), came up with a fix that solved it (add lower voicing), but we created another problem (other voicings are now too low)\\u2026\\nThis often happens when we are using a wrong abstraction, in this case, using root transposition to create voicings.\"), mdx(\"p\", null, \"The essential problem: We end up having different ranges for different roots. Also, we have no direct control over the range of the voicings.\\nAdditionally, it does not feel right for a voicing appear twice in the dictionary, only differing in octave.\"), mdx(\"h3\", {\n    \"id\": \"what-makes-a-voicing-unpleasant\"\n  }, \"What makes a voicing unpleasant\"), mdx(\"p\", null, \"When a voicing gets too low, some intervals at the bottom end are getting so close together that their overtones create nasty dissonances, as they get more and more audible.\"), mdx(\"h3\", {\n    \"id\": \"solution\"\n  }, \"Solution\"), mdx(\"p\", null, \"It would be great to control the range directly, not indirectly through the dictionary. Let\\u2019s remove the clutter from our dictionary:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"export const lefthand = {\\n  m7: ['3m 5P 7m 9M', '7m 9M 10m 12P'],\\n  '7': ['3M 6M 7m 9M', '7m 9M 10M 13M'],\\n  '^7': ['3M 5P 7M 9M', '7M 9M 10M 12P']\\n};\\n\")), mdx(\"p\", null, \"Now I want to find a way to get all possible voicings inside a given note range. Lets use:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"['G2', 'C5'];\\n\")), mdx(\"p\", null, \"like proposed \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://youtu.be/5uoD6LfaDoE?t=523\"\n  }), \"here\"), \".\"), mdx(\"p\", null, \"Now we want this:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"const possibleVoicings = voicingsInRange('Cm7', lefthand, ['G2', 'C5']);\\n/* [\\n  ['Eb3','G3','Bb3','D4'],\\n  ['Bb2','D3','Eb3','G3'],\\n  ['Bb3','D4','Eb4','G4'],\\n]*/\\n\")), mdx(\"p\", null, \"Now those 3 voicings are all possible Cm7 voicings inside the given range, using the provided dictionary.\"), mdx(Player, {\n    fold: false,\n    instruments: {\n      tinypiano: tinypiano\n    },\n    events: renderRhythmObject({\n      duration: 4,\n      sequential: [{\n        parallel: ['Bb2', 'D3', 'Eb3', 'G3']\n      }, {\n        parallel: ['Eb3', 'G3', 'Bb3', 'D4']\n      }, {\n        parallel: ['Bb3', 'D4', 'Eb4', 'G4'],\n        duration: 2\n      }]\n    }),\n    mdxType: \"Player\"\n  }), mdx(\"h3\", {\n    \"id\": \"proper-range-implementation\"\n  }, \"Proper Range Implementation\"), mdx(\"p\", null, \"After some back and forth, I ended up implementing the method like this:\"), mdx(\"div\", {\n    style: {\n      \"maxHeight\": \"400px\",\n      \"overflow\": \"auto\",\n      \"borderRadius\": \"10px\",\n      \"marginBottom\": \"10px\"\n    }\n  }, mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"import { Chord, Range, Note, Interval } from '@tonaljs/tonal';\\n\\nexport function voicingsInRange(chord, dictionary, range) {\\n  const { tonic, aliases } = Chord.get(chord);\\n  // find equivalent symbol that is used as a key in dictionary:\\n  const symbol = Object.keys(dictionary).find((_symbol) =>\\n    aliases.includes(_symbol)\\n  );\\n  // resolve array of interval arrays for the wanted symbol\\n  const voicings = dictionary[symbol].map((intervals) => intervals.split(' '));\\n  const notesInRange = Range.chromatic(range); // gives array of notes inside range\\n  return voicings.reduce((voiced, voicing) => {\\n    // transpose intervals relative to first interval (e.g. 3m 5P > 1P 3M)\\n    const relativeIntervals = voicing.map((interval) =>\\n      Interval.substract(interval, voicing[0])\\n    );\\n    // interval from bottom to top note\\n    const voicingSpan = relativeIntervals[relativeIntervals.length - 1];\\n    // get enharmonic correct pitch class the bottom note\\n    const bottomPitchClass = Note.transpose(tonic, voicing[0]);\\n    // get all possible start notes for voicing\\n    const starts = notesInRange\\n      // only get the start notes:\\n      .filter((note) => Note.chroma(note) === Note.chroma(bottomPitchClass))\\n      // filter out start notes that will overshoot the top end of the range\\n      .filter(\\n        (note) =>\\n          Note.midi(Note.transpose(note, voicingSpan)) <= Note.midi(range[1])\\n      )\\n      // replace Range.chromatic notes with the correct enharmonic equivalents\\n      .map((note) => enharmonicEquivalent(note, bottomPitchClass));\\n    // render one voicing for each start note\\n    const notes = starts.map((start) =>\\n      relativeIntervals.map((interval) => Note.transpose(start, interval))\\n    );\\n    return voiced.concat(notes);\\n  }, []);\\n}\\n\"))), mdx(\"p\", null, \"using \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/tonaljs/tonal/tree/master/packages/range\"\n  }), \"Range.chromatic\"), \" to create the range + a custom enharmonicEquivalent function to get the accidentals right.\"), mdx(\"h4\", {\n    \"id\": \"enharmonic-considerations\"\n  }, \"Enharmonic Considerations\"), mdx(\"p\", null, \"One tricky part of the implementation above was the enharmonicEquivalent method.\"), mdx(\"p\", null, \"To understand the problem, let\\u2019s try to create an edge case, by rendering the chord Fm7b5 with a specific voicing:\"), mdx(\"div\", {\n    style: {\n      \"maxHeight\": \"400px\",\n      \"overflow\": \"auto\",\n      \"borderRadius\": \"10px\",\n      \"marginBottom\": \"10px\"\n    }\n  }, mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"const tonic = 'F';\\nlet voicing = ['5d 7m 8P 10m'];\\nconst range = ['A2', 'C4'];\\nconst notesInRange = Range.chromatic(range);\\n// ['A2','Bb2','B2','C3','Db3','D3','Eb3','E3','F3','Gb3','G3','Ab3','A3','Bb3','B3','C4']\\nvoicing = voicing.split(' '); // ['5d', '7m', '8P', '10m']\\n// map intervals relative to start\\nconst relativeIntervals = voicing.map((interval) =>\\n  Interval.substract(interval, voicing[0])\\n); // ['1P', '3M', '4A', '6M']\\n// interval from bottom to top note:\\nconst voicingSpan = relativeIntervals[relativeIntervals.length - 1]; // 6M\\n// find out the bottom pitch class\\nconst bottomPitchClass = Note.transpose(tonic, voicing[0]); // F + 5d = Cb\\n// filter the range\\nlet starts = notesInRange\\n  // .. only keep notes that are enharmonically equivalent to Cb\\n  .filter((note) => Note.chroma(note) === Note.chroma(bottomPitchClass)) // ['B2','B3']\\n  // .. only keep notes that stay within range when added the voicingSpan\\n  .filter(\\n    (note) =>\\n      Note.midi(Note.transpose(note, voicingSpan)) <= Note.midi(range[1])\\n  ); // ['B2']\\n// .map(note => enharmonicEquivalent(note, bottomPitchClass)) // intentionally left out\\n// render one voicing for each start note\\nconst notes = starts.map((start) =>\\n  relativeIntervals.map((interval) => Note.transpose(start, interval))\\n); // ['1P', '3M', '4A', '6M'].map((interval) => Note.transpose('B2', interval))\\n// yields ['B2','D#3','E#3', 'G#3']\\n// but we want ['Cb3','Eb3','F3','Ab3']\\n\"))), mdx(\"p\", null, \"So the last piece of the puzzle is a function that turns the B2 to a Cb3 before calculating the notes.\"), mdx(\"p\", null, \"My first attempt at this was just swapping the octave number:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"function enharmonicEquivalent(note, pitchClass) {\\n  const { oct } = Note.get(note);\\n  return pitchClass + oct;\\n}\\n// enharmonicEquivalent('F2', 'E#') => E#2 => fine\\n// enharmonicEquivalent('B2', 'Cb') => Cb2 => not fine => 1 octave too low\\n// enharmonicEquivalent('C2', 'B#') => B#2 => not fine => 1 octave too high\\n\")), mdx(\"p\", null, \"But for cases where the enharmonic equivalents have a different octave number, this results in octave shifts.\\nI finally implemented it like this:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-ts\"\n  }), \"export function enharmonicEquivalent(note: string, pitchClass: string): string {\\n  const { alt, letter } = Note.get(pitchClass);\\n  let { oct } = Note.get(note);\\n  const letterChroma = Note.chroma(letter) + alt;\\n  if (letterChroma > 11) {\\n    oct--;\\n  } else if (letterChroma < 0) {\\n    oct++;\\n  }\\n  return pitchClass + oct;\\n}\\n// enharmonicEquivalent('F2', 'E#') => E#2 => fine\\n// enharmonicEquivalent('B2', 'Cb') => Cb3 => fine\\n// enharmonicEquivalent('C2', 'B#') => B#1 => fine\\n\")), mdx(\"h3\", {\n    \"id\": \"conclusion\"\n  }, \"Conclusion\"), mdx(\"p\", null, \"Finally the \\u201Cproblematic\\u201D chord progression sounds like this:\"), mdx(Player, {\n    fold: false,\n    instruments: {\n      tinypiano: tinypiano,\n      drums: drums\n    },\n    events: renderRhythmObject({\n      duration: 12,\n      sequential: ['Cm7', 'Em7', 'Dm7', 'Cm7', 'Em7', 'Dm7', {\n        value: 'Cm7',\n        duration: 2\n      }, {\n        value: 'Bm7',\n        duration: 2\n      }]\n    }).reduce(voicingReducer(lefthand, ['C3', 'C6']), []),\n    mdxType: \"Player\"\n  }), mdx(\"details\", null, mdx(\"summary\", null, \"show source\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Player\\n  fold={false}\\n  instruments={{ tinypiano, drums }}\\n  events={renderRhythmObject({\\n    duration: 12,\\n    sequential: [\\n      'Cm7',\\n      'Em7',\\n      'Dm7',\\n      'Cm7',\\n      'Em7',\\n      'Dm7',\\n      { value: 'Cm7', duration: 2 },\\n      { value: 'Bm7', duration: 2 }\\n    ]\\n  }).reduce(voicingReducer(lefthand, ['C3', 'C6']), [])}\\n/>\\n\"))), mdx(\"br\", null), mdx(\"p\", null, \"Now this seems to work perfectly, the only jump remains at the repetition, which could be fixed by regenerating the voicing each round, which I will implement in the future.\"), mdx(\"p\", null, \"Now to close the gap, here\\u2019s the basic cadence again, this time generated algorithmically:\"), mdx(Player, {\n    fold: true,\n    instruments: {\n      tinypiano: tinypiano\n    },\n    events: renderRhythmObject({\n      duration: 4,\n      sequential: [['F', 'G'], 'C']\n    }).reduce(voicingReducer({\n      M: ['1P 3M 5P', '3M 5P 8P', '5P 8P 10M']\n    }, ['C3', 'A4']), []),\n    mdxType: \"Player\"\n  }), mdx(\"details\", null, mdx(\"summary\", null, \"show source\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Player\\n  fold={true}\\n  instruments={{ tinypiano }}\\n  events={renderRhythmObject({\\n    duration: 4,\\n    sequential: [['F', 'G'], 'C']\\n  }).reduce(\\n    voicingReducer(\\n      {\\n        M: ['1P 3M 5P', '3M 5P 8P', '5P 8P 10M']\\n      },\\n      ['C3', 'A4']\\n    ),\\n    []\\n  )}\\n/>\\n\"))), mdx(\"p\", null, \"Let\\u2019s try some autumn leaves (with more voicings added to the dictionary):\"), mdx(Player, {\n    instruments: {\n      piano: piano\n    },\n    fold: false,\n    events: renderRhythmObject({\n      duration: 64,\n      sequential: [['Cm7', 'F7', 'Bb^7', 'Eb^7'], ['Am7b5', 'D7b13', 'Gm6', '_'], ['Cm7', 'F7', 'Bb^7', 'Eb^7'], ['Am7b5', 'D7b13', 'Gm6', '_'], ['Am7b5', 'D7b13', 'Gm6', '_'], ['Cm7', 'F7', 'Bb^7', 'Eb^7'], ['Am7b5', 'D7b13', ['Gm7', 'Gb7'], ['Fm7', 'E7']], ['Am7b5', 'D7b13', 'Gm6', '_']]\n    }).reduce(tieReducer(), []).reduce(voicingReducer(lefthand, ['D3', 'E5']), []),\n    mdxType: \"Player\"\n  }), mdx(\"details\", null, mdx(\"summary\", null, \"show source\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"<Player\\n  instruments={{ piano }}\\n  fold={false}\\n  events={renderRhythmObject({\\n    duration: 64,\\n    sequential: [\\n      ['Cm7', 'F7', 'Bb^7', 'Eb^7'],\\n      ['Am7b5', 'D7b13', 'Gm6', '_'],\\n      ['Cm7', 'F7', 'Bb^7', 'Eb^7'],\\n      ['Am7b5', 'D7b13', 'Gm6', '_'],\\n      ['Am7b5', 'D7b13', 'Gm6', '_'],\\n      ['Cm7', 'F7', 'Bb^7', 'Eb^7'],\\n      ['Am7b5', 'D7b13', ['Gm7', 'Gb7'], ['Fm7', 'E7']],\\n      ['Am7b5', 'D7b13', 'Gm6', '_']\\n    ]\\n  })\\n    .reduce(tieReducer(), [])\\n    .reduce(voicingReducer(lefthand, ['E3', 'G5']), [])}\\n/>\\n\"))), mdx(\"br\", null), mdx(\"h2\", {\n    \"id\": \"tbd\"\n  }, \"TBD\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"error handling !\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"remove hard coded bass from voicingReducer => add bassReducer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"add filterReducer + combineReducers => apply voicing reducer only to chords\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"add duplicateReducer (removes duplicate events) => remove notes that are covered by melody\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"add rangeReducer (remove notes outside a certain range) => remove notes above melody\")));\n}\n;\nMDXContent.isMDXComponent = true;","slug":"/rhythmical-chords/","title":"Rhythmical Chords","tags":[],"keywords":[],"date":"July 30, 2020"},"previous":{"__typename":"MdxBlogPost","id":"9e8bfe92-aaaa-5c24-8aba-a0e97de3211d","excerpt":"In modern music, ties across barlines are a common way of adding interest to a melody. For example, take the beginning of the tune \"Blue…","slug":"/rhythmical-ties/","title":"Rhythmical Ties","date":"July 10, 2020"},"next":{"__typename":"MdxBlogPost","id":"35bc9fc8-9385-5688-a480-3383b7827fb8","excerpt":"So far, rhythmical knows two ways of data transformation/mutation: plugins  as preprocessors reducers  as postprocessors In this post, I…","slug":"/rhythmical-reducers/","title":"Rhythmical Mutations","date":"August 02, 2020"}},"pageContext":{"id":"2b49a6a1-d665-5745-b2b9-71579ed46c30","previousId":"9e8bfe92-aaaa-5c24-8aba-a0e97de3211d","nextId":"35bc9fc8-9385-5688-a480-3383b7827fb8"}}}